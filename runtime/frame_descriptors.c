/**************************************************************************/
/*                                                                        */
/*                                 OCaml                                  */
/*                                                                        */
/*      KC Sivaramakrishnan, Indian Institute of Technology, Madras       */
/*                   Tom Kelly, OCaml Labs Consultancy                    */
/*                 Stephen Dolan, University of Cambridge                 */
/*                                                                        */
/*   Copyright 2019 Indian Institute of Technology, Madras                */
/*   Copyright 2021 OCaml Labs Consultancy Ltd                            */
/*   Copyright 2019 University of Cambridge                               */
/*                                                                        */
/*   All rights reserved.  This file is distributed under the terms of    */
/*   the GNU Lesser General Public License version 2.1, with the          */
/*   special exception on linking described in the file LICENSE.          */
/*                                                                        */
/**************************************************************************/

#define CAML_INTERNALS

#include "caml/platform.h"
#include "caml/frame_descriptors.h"
#include "caml/major_gc.h" /* for caml_major_cycles_completed */
#include "caml/memory.h"
#include "caml/fail.h"
#include "caml/shared_heap.h"
#include <stddef.h>

/* Defined in code generated by ocamlopt */
extern intnat * caml_frametable[];

/* Note: [cur] is bound by this macro */
#define iter_list(list,cur) \
  for (caml_frametable_list *cur = list; cur != NULL; cur = cur->next)

static frame_descr * next_frame_descr(frame_descr * d) {
  unsigned char num_allocs = 0, *p;
  CAMLassert(d->retaddr >= 4096);
  if (d->frame_size != 0xFFFF) {
    /* Skip to end of live_ofs */
    p = (unsigned char*)&d->live_ofs[d->num_live];
    /* Skip alloc_lengths if present */
    if (d->frame_size & 2) {
      num_allocs = *p;
      p += num_allocs + 1;
    }
    /* Skip debug info if present */
    if (d->frame_size & 1) {
      /* Align to 32 bits */
      p = Align_to(p, uint32_t);
      p += sizeof(uint32_t) * (d->frame_size & 2 ? num_allocs : 1);
    }
    /* Align to word size */
    p = Align_to(p, void*);
    return ((frame_descr*) p);
  } else {
    /* This marks the top of an ML stack chunk. Skip over empty
     * frame descriptor */
    /* Skip to address of zero-sized live_ofs */
    CAMLassert(d->num_live == 0);
    p = (unsigned char*)&d->live_ofs[0];
    /* Align to word size */
    p = Align_to(p, void*);
    return ((frame_descr*) p);
  }
}

static intnat count_descriptors(caml_frametable_list *list) {
  intnat num_descr = 0;
  iter_list(list,cur) {
    num_descr += *((intnat*) cur->frametable);
  }
  return num_descr;
}

static caml_frametable_list* frametables_list_tail(caml_frametable_list *list) {
  caml_frametable_list *tail = NULL;
  iter_list(list,cur) {
    tail = cur;
  }
  return tail;
}

static int capacity(caml_frame_descrs table) {
  int capacity = table.mask + 1;
  CAMLassert(capacity == 0 || Is_power_of_2(capacity));
  return capacity;
}

static void fill_hashtable(
  caml_frame_descrs *table, caml_frametable_list *new_frametables)
{
  iter_list(new_frametables,cur) {
    intnat * tbl = (intnat*) cur->frametable;
    intnat len = *tbl;
    frame_descr * d = (frame_descr *)(tbl + 1);
    for (intnat j = 0; j < len; j++) {
      uintnat h = Hash_retaddr(d->retaddr, table->mask);
      while (table->descriptors[h] != NULL) {
        h = (h+1) & table->mask;
      }
      table->descriptors[h] = d;
      d = next_frame_descr(d);
    }
  }
}

static void add_frame_descriptors(
  caml_frame_descrs *table,
  caml_frametable_list *new_frametables)
{
  CAMLassert(new_frametables != NULL);

  caml_frametable_list *tail = frametables_list_tail(new_frametables);
  intnat increase = count_descriptors(new_frametables);
  intnat tblsize = capacity(*table);

  /* The size of the hashtable is a power of 2 that must remain
     greater or equal to 2 times the number of descriptors. */

  /* Reallocate the caml_frame_descriptor table if it is too small */
  if(tblsize < (table->num_descr + increase) * 2) {

    /* Merge both lists */
    tail->next = table->frametables;
    table->frametables = NULL;

    /* [num_descr] can be less than [num_descr + increase] if frame
       tables were unregistered */
    intnat num_descr = count_descriptors(new_frametables);

    tblsize = 4;
    while (tblsize < 2 * num_descr) tblsize *= 2;

    table->num_descr = num_descr;
    table->mask = tblsize - 1;

    if (table->descriptors != NULL) caml_stat_free(table->descriptors);
    table->descriptors =
      (frame_descr **) caml_stat_calloc_noexc(tblsize, sizeof(frame_descr *));
    if (table->descriptors == NULL) caml_raise_out_of_memory();

    fill_hashtable(table, new_frametables);
  } else {
    table->num_descr += increase;
    fill_hashtable(table, new_frametables);
    tail->next = table->frametables;
  }

  table->frametables = new_frametables;
}

static caml_frame_descrs build_frame_descriptors(
  caml_frametable_list* frametables)
{
  caml_frame_descrs table = { 0, -1, NULL, NULL };

  add_frame_descriptors(&table, frametables);

  return table;
}

/* Memory used by frametables is only freed once a GC cycle has
   completed, because other threads access the frametable at
   unpredictable times. */
struct frametable_version {
  caml_frame_descrs table;

  /* after this cycle has completed,
     the previous table should be deallocated.
     Set to No_need_to_free after prev is freed */
  atomic_uintnat free_prev_after_cycle;
  struct frametable_version* prev;
};
#define No_need_to_free ((uintnat)(-1))

struct frametable_version *current_frametable = NULL;

static caml_frametable_list *cons(
  intnat *frametable, caml_frametable_list *tl)
{
  caml_frametable_list *li = caml_stat_alloc(sizeof(caml_frametable_list));
  li->frametable = frametable;
  li->next = tl;
  return li;
}

void caml_init_frame_descriptors(void)
{
  int i;
  struct frametable_version *ft;
  caml_frametable_list *frametables = NULL;

  /* `init_frame_descriptors` is called from `init_gc`, befor
     any mutator can run. */

  for (i = 0; caml_frametable[i] != 0; i++)
    frametables = cons(caml_frametable[i], frametables);

  ft = caml_stat_alloc(sizeof(*ft));
  ft->table = build_frame_descriptors(frametables);
  atomic_store_rel(&ft->free_prev_after_cycle, No_need_to_free);
  ft->prev = 0;
  current_frametable = ft;
}

typedef struct frametable_array {
  void **table;
  int ntables;
} frametable_array;

static void register_frametables(frametable_array *array)
{
  int i;
  struct frametable_version *ft, *old;

  old = current_frametable;
  CAMLassert(old != NULL);

  /* Free the old table(s) if it is safe to do so */
  if (atomic_load_acq(&old->free_prev_after_cycle) < caml_major_cycles_completed)
  {
    if (old->prev != NULL) {
      struct frametable_version *p = old->prev;
      while (p != NULL) {
        struct frametable_version *next = p->prev;
        caml_stat_free(p->table.descriptors);
        caml_stat_free(p);
        p = next;
      }
      old->prev = NULL;
      atomic_store_rel(&old->free_prev_after_cycle, No_need_to_free);
    }
  }

  /* The frametable list of the new version is the frametable list of
     the old version, plus the new frametables. */
  caml_frametable_list *frametables = old->table.frametables;
  for (i = 0; i < array->ntables; i++)
    frametables = cons((intnat*)array->table[i], frametables);

  /* The hashtable is recomputed from scratch from the new
     frametable list.

     FIXME: repeating this linear reconstruction on each registration
     leads to quadratic behavior. */
  ft = caml_stat_alloc(sizeof(*ft));
  ft->table = build_frame_descriptors(frametables);
  atomic_store_rel(&ft->free_prev_after_cycle, caml_major_cycles_completed);
  ft->prev = old;
  current_frametable = ft;

  /* Ensure that we GC often enough to prevent more than 1/4 of
     heap memory being stale frame tables */
  caml_adjust_gc_speed(
     /* Size of the table just allocated */
     (sizeof(*ft) + sizeof(ft->table.descriptors[0]) * capacity(ft->table)),
     /* 1/4 of the heap size */
     caml_heap_size(Caml_state->shared_heap) / 4
  );
}

static void stw_register_frametables(
    caml_domain_state* domain,
    void* frametables,
    int participating_count,
    caml_domain_state** participating)
{
  barrier_status b = caml_global_barrier_begin ();

  if (caml_global_barrier_is_final(b)) {
    register_frametables((frametable_array*) frametables);
  }

  caml_global_barrier_end(b);
}

void caml_register_frametables(void **table, int ntables) {
  struct frametable_array frametables = { table, ntables };
  do {} while (!caml_try_run_on_all_domains(
                 &stw_register_frametables, &frametables, 0));
}

caml_frame_descrs caml_get_frame_descrs(void)
{
  CAMLassert(current_frametable);
  return current_frametable->table;
}

frame_descr* caml_find_frame_descr(caml_frame_descrs fds, uintnat pc)
{
  frame_descr * d;
  uintnat h;

  h = Hash_retaddr(pc, fds.mask);
  while (1) {
    d = fds.descriptors[h];
    if (d == 0) return NULL; /* can happen if some code compiled without -g */
    if (d->retaddr == pc) break;
    h = (h+1) & fds.mask;
  }
  return d;
}
